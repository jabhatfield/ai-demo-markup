= Zoo Chatbot deep dive
:navtitle: Deep dive
:icons: font
:xrefstyle: short

This deep dive outlines the main concepts of the Zoo Chatbot inner workings.

== Natural Language Processing

*Natural Language Processing* (*NLP*) is the leverage of computing to understand language. It involves a variety of
linguistic datasets, or _corpora_, along with associated algorithms that process this data to form language models.
Zoo Chatbot implements https://opennlp.apache.org[OpenNLP,window=_blank] to perform the following NLP tasks, which are
explained in following sections:

* <<_tokenization>>
* <<_part_of_speech_tagging>>
* <<_lemmatization>>
* <<_categorisation>>

== Tokenization

Zoo Chatbot tokenizes a message into its constituent parts, such as words and punctuation marks, for subsequent
<<_part_of_speech_tagging>>. Words are predominantly segmented by white space, with punctuation marks potentially attached
in the case of abbreviations. Tokenization decisions are based on a maximum entropy algorithm, which operates on a
pre-trained model of tokenization data.

statistical model and Zoo Chatbot implements
a maximum entropy

pre-trained model of tokenization data

, with the assistance of
a pre-trained model.

TODO uses max ent

== Part-of-speech tagging

== Lemmatization

== Categorisation

inc bag of words - words as numbers

== Learn more

* See the xref:tutorial/chat-tutorial.adoc[] for a practical guide of operations.
* See the xref:intro-component::api-spec.adoc[] for the full specification.